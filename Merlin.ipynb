{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programa Nº 1:\n",
    "\n",
    "-----\n",
    "\n",
    "## WordCloud Exploration\n",
    "\n",
    "1. WordCloud I<br />\n",
    "    1.1. Preprocesamiento y Procesamiento<br />\n",
    "        - Preprocesamiento: Feature extracción, ajuste del content en su conjunto, tokenización<br />\n",
    "        - Procesamiento: Implementación de filtros para la limpieza y filtros para la selección de muestras<br />\n",
    "    1.2. Tratamiento y Generación de WordCloud<br />\n",
    "        - Tratamiento: Aplicación de stop_words por medio de modelo IA (spacy)<br />\n",
    "        - Generación WC: Uno para la feature \"content_wc\" y otro para la feature \"token_wc\"<br />\n",
    "    1.3 Agregación:<br />\n",
    "        - Agregación en el sentido de la estructura de datos, el programa recibe un fichero con extensión<br />\n",
    "            \".csv\" y devuelve una lista Python, el primer elemento es \"dataframes\" y el segundo \"wordcloud_storage\"<br />\n",
    "        - dataframes: Es un diccionario Python, en su interior hay 1 pandas.DataFrame por cada filtro booleano<br />\n",
    "            se haya implementado. Por default no hay filtros booleanos implementados, por lo tanto el diccionario<br />\n",
    "            tendría la siguiente forma ```{'csv_filename': [pd.DataFrame(...)]}``` con todo el contenido del batch.<br />\n",
    "        - wordcloud_storage: Es un diccionario Python, en su interior posee las instancias de clase del objeto tipo<br />\n",
    "            WordCloud de la librería wordcloud. La App utiliza dos features, \"content_wc\", y \"token_wc\", por lo tanto,<br />\n",
    "            siguiendo con el ejemplo de no aplicar ningún filtro booleano, el segundo elemento de la lista de agregación<br />\n",
    "            sería así ```{'csv_filename': [ [WC_content, WC_token] ] }```.<br />\n",
    "        - El output del set de aplicaciones resulta entonces, ```result = [{...}, {...}]``` - el primer diccionario es<br />\n",
    "            dataframes, y el segundo wordcloud_storage<br />\n",
    "    1.4 Outputs:<br />\n",
    "        - El programa fue pensado para obtener un primer approach a lo que el contenido refleja en su conjunto<br />\n",
    "        - Optimizar la extracción de muestras por medio de multi-hilos, durante el proceso de stop_words<br />\n",
    "        - wordcloud.WordCloud permite obtener imágenes, texto, y campos vectoriales por medio de la implementación<br />\n",
    "            de sus métodos internos, to_image(), to_svg(), to_array(), respectivamente.<br />\n",
    "        - Brindar al usuario flexibilidad en los outputs, por medio de implementación de máscaras, filtros de palabras,<br />\n",
    "            configuraciónes preseteadas, y demás.<br />\n",
    "        - Un resplado en .txt de la última configuración utilizada para cada máscara.<br />\n",
    "\n",
    "2. Clasificación de Sentimiento y Emociones<br />\n",
    "    2.1 Prepocesamiento y Procesamiento<br />\n",
    "        - Preprocesamiento: Feature extracción, ajuste del content en su conjunto, tokenización<br />\n",
    "        - Procesamiento: Time Series adjustment, agregación de variables temporales<br />\n",
    "    2.2 Transformers:<br />\n",
    "        - Multiprocesos: Paralelización los modelos de Emociones<br />\n",
    "        - Sentimiento: 3 modelos M1_I, M1_II, y M1_III<br />\n",
    "            + M1_I: Optimización por multihilos, sub-batches secuenciales<br />\n",
    "            + M1_II: Ingesta por Data Streaming mediante Python Generators<br />\n",
    "            + M1_III: Ingesta por Data Streaming mediante Python Generators<br />\n",
    "        - Emociones: 2 modelos M2, y M3<br />\n",
    "            + M2: Ingesta por Data Streaming mediante Python Generators<br />\n",
    "            + M3: Ingesta por Data Streaming mediante Python Generators<br />\n",
    "    2.3 Analíticas:<br />\n",
    "        - Gráficos: Línea de tiempo, Gráficos Radiales, Gráficos de Barras<br />\n",
    "        - Outputs: Ficheros .csv y .txt con resumen descriptivo<br />\n",
    "\n",
    "3. WordCloud II:<br />\n",
    "    3.1 Lectura de clasificaciones<br />\n",
    "        - Definir filtros booleanos para cada muestra<br />\n",
    "    3.2 Tratamiento y Generación de WordCloud<br />\n",
    "        - Tratamiento: Extracción con filtros, implementación de multi-hilos para stop_words<br />\n",
    "        - Generación WC: Una lista por cada muestra y un objeto por cada feature.<br />\n",
    "    3.3 Agregación:<br />\n",
    "    3.4 Outputs<br />\n",
    "\n",
    "\n",
    "4. Identificación de Tópicos: es otra notebook que creo que se llama Lotto.\n",
    "            M4: Optimización por multihilos, sub-batches paralelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"___main___results.pkl\", \"rb\") as f:\n",
    "    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
